{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import bertopic\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(f\"{data_directory}/data.parquet\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_directory}/vocabulary.json\") as f:\n",
    "    vocabulary = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA run\n",
    "X_bow = gensim.matutils.Scipy2Corpus(np.array([d[\"bow\"] for d in data]))\n",
    "num_topicss = [50, 100, 150, 200, 250, 300]\n",
    "num_repeats = 5\n",
    "\n",
    "idx2vocab = {v[\"idx\"]: k for k, v in vocabulary.items()}\n",
    "\n",
    "\n",
    "def run_lda(num_topics):\n",
    "    lda = gensim.models.LdaModel(X_bow, num_topics=num_topics, id2word=idx2vocab)\n",
    "    topic_probs = lda.show_topics(\n",
    "        num_topics=num_topics,\n",
    "        formatted=False,\n",
    "    )\n",
    "    topics = [[word for word, _ in topic] for _, topic in topic_probs]\n",
    "    return topics\n",
    "\n",
    "for num_topics in num_topicss:\n",
    "    print(f\"num_topics={num_topics}\")\n",
    "    for i in range(num_repeats):\n",
    "        print(f\"repeat={i}\")\n",
    "        topics = run_lda(num_topics)\n",
    "        output = {\n",
    "            \"model\": \"lda\",\n",
    "            \"num_topics\": num_topics,\n",
    "            \"topics\": topics,\n",
    "        }\n",
    "        with open(f\"ignore/output.jsonl\", \"a\") as f:\n",
    "            f.write(json.dumps(output) + \"\\n\")\n",
    "X_tfidf = gensim.matutils.Scipy2Corpus(np.array([d[\"tfidf\"] for d in data]))\n",
    "\n",
    "def run_lda_tfidf(num_topics):\n",
    "    lda = gensim.models.LdaModel(X_tfidf, num_topics=num_topics, id2word=idx2vocab)\n",
    "    topic_probs = lda.show_topics(\n",
    "        num_topics=num_topics,\n",
    "        formatted=False,\n",
    "    )\n",
    "    topics = [[word for word, _ in topic] for _, topic in topic_probs]\n",
    "    return topics\n",
    "\n",
    "\n",
    "for num_topics in num_topicss:\n",
    "    print(f\"num_topics={num_topics}\")\n",
    "    for i in range(num_repeats):\n",
    "        print(f\"repeat={i}\")\n",
    "        topics = run_lda(num_topics)\n",
    "        output = {\n",
    "            \"model\": \"lda_tf_idf\",\n",
    "            \"num_topics\": num_topics,\n",
    "            \"topics\": topics,\n",
    "        }\n",
    "        with open(f\"ignore/output_lda.jsonl\", \"a\") as f:\n",
    "            f.write(json.dumps(output) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [d[\"text\"] for d in data]\n",
    "embeddings = np.array([d[\"embedding\"] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_topics=50\n",
      "repeat=0\n",
      "repeat=1\n",
      "repeat=2\n",
      "repeat=3\n",
      "repeat=4\n",
      "num_topics=100\n",
      "repeat=0\n",
      "repeat=1\n",
      "repeat=2\n",
      "repeat=3\n",
      "repeat=4\n",
      "num_topics=150\n",
      "repeat=0\n",
      "repeat=1\n",
      "repeat=2\n",
      "repeat=3\n",
      "repeat=4\n",
      "num_topics=200\n",
      "repeat=0\n",
      "repeat=1\n",
      "repeat=2\n",
      "repeat=3\n",
      "repeat=4\n",
      "num_topics=250\n",
      "repeat=0\n",
      "repeat=1\n",
      "repeat=2\n",
      "repeat=3\n",
      "repeat=4\n",
      "num_topics=300\n",
      "repeat=0\n",
      "repeat=1\n",
      "repeat=2\n",
      "repeat=3\n",
      "repeat=4\n"
     ]
    }
   ],
   "source": [
    "def fit_bertopic(num_topics):\n",
    "    model = bertopic.BERTopic(language=\"multilingual\", nr_topics=num_topics)\n",
    "    model.fit_transform(texts, embeddings)\n",
    "    topics = model.get_topic_info()[\"Representation\"].tolist()\n",
    "    return topics\n",
    "\n",
    "\n",
    "num_topicss = [50, 100, 150, 200, 250, 300]\n",
    "num_repeats = 5\n",
    "\n",
    "for num_topics in num_topicss:\n",
    "    print(f\"num_topics={num_topics}\")\n",
    "    for i in range(num_repeats):\n",
    "        print(f\"repeat={i}\")\n",
    "        topics = fit_bertopic(num_topics)\n",
    "        output = {\n",
    "            \"model\": \"bertopic\",\n",
    "            \"num_topics\": num_topics,\n",
    "            \"topics\": topics,\n",
    "        }\n",
    "        with open(f\"ignore/output_lda.jsonl\", \"a\") as f:\n",
    "            f.write(json.dumps(output) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import octis.models.contextualized_topic_models.datasets.dataset\n",
    "import octis.models.contextualized_topic_models.models.ctm\n",
    "\n",
    "\n",
    "def fit_ctm(data, dataset, num_topics, num_epochs, vocabulary):\n",
    "    model = octis.models.contextualized_topic_models.models.ctm.CTM(\n",
    "        input_size=len(vocabulary),\n",
    "        bert_input_size=len(data[0][\"embedding\"]),\n",
    "        num_topics=num_topics,\n",
    "        num_epochs=num_epochs,\n",
    "    )\n",
    "    model.fit(dataset)\n",
    "    topics = model.get_topics()\n",
    "\n",
    "    return topics\n",
    "\n",
    "\n",
    "def run():\n",
    "    dataset = octis.models.contextualized_topic_models.datasets.dataset.CTMDataset(\n",
    "        # X=np.array([d[\"bow\"] for d in data]),\n",
    "        X=np.array([d[\"tfidf\"] for d in data]),\n",
    "        X_bert=np.array([d[\"embedding\"] for d in data]),\n",
    "        idx2token={i[\"idx\"]: word for word, i in vocabulary.items()},\n",
    "    )\n",
    "\n",
    "    num_topicss = [50, 100, 150, 200, 250, 300]\n",
    "    num_epochs = 100\n",
    "    num_repeats = 5\n",
    "\n",
    "    for num_topics in num_topicss:\n",
    "        for i in range(num_repeats):\n",
    "            topics = fit_ctm(data, dataset, num_topics, num_epochs, vocabulary)\n",
    "            output = {\n",
    "                # \"model\": \"ctm\",\n",
    "                \"model\": \"ctm_tfidf\",\n",
    "                \"num_topics\": num_topics,\n",
    "                \"topics\": topics,\n",
    "            }\n",
    "            with open(\"ignore/output.jsonl\", \"a\") as f:\n",
    "                f.write(json.dumps(output) + \"\\n\")\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_code-idiVf7sk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
